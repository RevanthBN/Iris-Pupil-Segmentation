{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris_segmentation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1-0pbWlzpMUI17kVZobKpnZVJrxEAzPbV",
      "authorship_tag": "ABX9TyPdCjuHJovdp6DPj4bpQE3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RevanthBN/Iris-Pupil-Segmentation/blob/main/Iris_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Figq3oF5zztZ"
      },
      "source": [
        "**Mounting the Google drive and cloning the github repo!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA_IPpD6sldN",
        "outputId": "96fd9627-d3db-4e8b-8513-8733666b18d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/Iris-Pupil-Segmentation/\n",
        "!git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Iris-Pupil-Segmentation\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFn-vGeFbWmj",
        "outputId": "a0c34ec3-0201-429b-aa70-34e820bbb9d0"
      },
      "source": [
        "!pip install segmentation-models-pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.6.3)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.10.0+cu102)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.4.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.62.3)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgyXDbyTiYFa"
      },
      "source": [
        "**Import all you want!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ647MAHc6xO"
      },
      "source": [
        "# Global libraries\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Python libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import *\n",
        "import math\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Others\n",
        "import time\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHbryJCc0deO"
      },
      "source": [
        "**Additional global variables**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7HwmrcsevCt"
      },
      "source": [
        "# Path for the training set\n",
        "train_images_path = glob('training_set/images/*')\n",
        "train_groundtruth_path = glob('training_set/groundtruths/*')\n",
        "train_masks_path = glob('training_set/masks/*')\n",
        "\n",
        "# Path for the test set\n",
        "test_images_path = glob('testing_set/images/*')\n",
        "test_groundtruth_path = glob('testing_set/groundtruths/*')\n",
        "test_masks_path = glob('testing_set/masks/*')\n",
        "\n",
        "# Image sizes for resizing\n",
        "width = 256\n",
        "height = 256\n",
        "dim = (width, height)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_iyQW4XOsfh"
      },
      "source": [
        "**Hyperparameters to be tuned**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxzcKoWsOsfi"
      },
      "source": [
        "# Percentage for the train-val split\n",
        "val_percent = 0.3\n",
        "\n",
        "# Number of workers for dataloader\n",
        "num_workers = 4 if cuda else 0 \n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 20\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 1e-4\n",
        "\n",
        "# Checkpoint path\n",
        "checkpoint_path = \"files/checkpoint.pth\"\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQK2cm5UN1Pq"
      },
      "source": [
        "**Loading the dataset from the cloned drive folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu8MwWU1N1Pq"
      },
      "source": [
        "class Iris(Dataset):\n",
        "    def __init__(self, images_path, masks_path):\n",
        "\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.n_samples = len(images_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "        image = image/255.0 ## (256, 256, 3)\n",
        "        image = np.transpose(image, (2, 0, 1))  ## (3, 256, 256)\n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_COLOR)\n",
        "        mask = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)\n",
        "        mask = mask/255.0   ## (256, 256, 3)\n",
        "        mask = np.transpose(mask, (2, 0, 1))  ## (3, 256, 256)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTIuN0yBNrF1"
      },
      "source": [
        "**Creating the datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TLbQ_VoJAzt"
      },
      "source": [
        "\"\"\" Creating the datasets \"\"\"\n",
        "train_dataset = Iris(train_images_path, train_masks_path)\n",
        "test_set = Iris(test_images_path, test_masks_path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlhk4VWO0nUj"
      },
      "source": [
        "**Splitting the train dataset into Training and Validation sets by a 70-30 split with a manual seed of 0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU8sDyY20nUk",
        "outputId": "79490412-1c15-4be1-bbb6-8905cb17ed5a"
      },
      "source": [
        "n_val = int(len(train_dataset) * val_percent)\n",
        "n_train = len(train_dataset) - n_val\n",
        "train_set, val_set = random_split(train_dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "data_str = f\"Dataset Size:\\nTrain: {len(train_set)} - Validation: {len(val_set)} - Test: {len(test_set)}\\n\"\n",
        "print(data_str)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size:\n",
            "Train: 379 - Validation: 162 - Test: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI1ic0Cy0n4v"
      },
      "source": [
        "**Loading the dataloader for the datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25QjE-Fn0n4v"
      },
      "source": [
        "# Training data\n",
        "train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=batch_size)\n",
        "train_loader = DataLoader(train_set, **train_loader_args)\n",
        "\n",
        "# Validation data\n",
        "val_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_set, **val_loader_args)\n",
        "\n",
        "# Testing data\n",
        "test_loader_args = dict(shuffle=False, num_workers=num_workers) if cuda\\\n",
        "                    else dict(shuffle=False,drop_last=True)\n",
        "test_loader = DataLoader(test_set, **test_loader_args)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzOQGwoP0nxv"
      },
      "source": [
        "\n",
        "**Dice Loss Function** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt0TPcKPfXGl"
      },
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJfDyT_fau5"
      },
      "source": [
        "\n",
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpToDxuG0nxx"
      },
      "source": [
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model = smp.Unet('resnet34', classes=3, activation='softmax')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
        "loss_fn = DiceBCELoss()\n",
        "model = model.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhxacnTNbjYt"
      },
      "source": [
        "**Training and Validation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfj3bLGIaa_o"
      },
      "source": [
        "def train(model, loader, optimizer, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        print(y_pred.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, loader, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAUdlNudgNsK"
      },
      "source": [
        "**Training and Evaluation of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "aeQRBom8gN9A",
        "outputId": "e3c69259-ac80-4d99-d169-4353b897ca87"
      },
      "source": [
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
        "\n",
        "    \"\"\" Saving the model \"\"\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
        "        print(data_str)\n",
        "\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
        "    data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
        "    data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
        "    print(data_str)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/base/modules.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.activation(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3, 256, 256])\n",
            "torch.Size([20, 1, 256, 256, 3])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ea9acc65441a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d1e7a37aac8d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3ce13b1e3a7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets, smooth)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdice_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mintersection\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mBCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mDice_BCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HTE3M49jNrGA",
        "outputId": "047299b2-fb45-4615-ee13-5d64e9083b2c"
      },
      "source": [
        "gg = 'training_set/masks/000008372_Ycrop_Hres_L.png'\n",
        "image = cv2.imread(gg, cv2.IMREAD_COLOR)\n",
        "print(image.shape)\n",
        "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, dim)\n",
        "image = image/255.0 ## (256, 256, 3)\n",
        "plt.imshow(image);\n",
        "plt.axis(\"off\");\n",
        "# image = np.transpose(image, (2, 0, 1))  ## (3, 256, 256)\n",
        "# image = image.astype(np.float32)\n",
        "# image = torch.from_numpy(image)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160, 224, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW6BCdiHi6f-",
        "outputId": "1c27921e-6981-4826-d8c6-6ee64e4c4df6"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unet(\n",
            "  (encoder): ResNetEncoder(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): UnetDecoder(\n",
            "    (center): Identity()\n",
            "    (blocks): ModuleList(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segmentation_head): SegmentationHead(\n",
            "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Identity()\n",
            "    (2): Activation(\n",
            "      (activation): Softmax(dim=None)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz8_Bpbui7oA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}